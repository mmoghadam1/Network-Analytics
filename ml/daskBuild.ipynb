{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kurtosis as kur, skew as skw, mode\n",
    "#import scipy.stats as sps\n",
    "from numpy import inf as npinf, nan as npnan\n",
    "import pandas as pd\n",
    "import gc\n",
    "gc.enable()\n",
    "from dask import dataframe as dd #, config as cfg\n",
    "from dask.distributed import Client, LocalCluster, wait\n",
    "from dask.array import stats as das\n",
    "from dask_ml.decomposition import PCA\n",
    "import joblib\n",
    "#cfg.set({'temporary_directory': '/tmp'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildall(features, stats, origin, origin_name):\n",
    "    if origin_name is 'src':\n",
    "        opposite = 'dest'\n",
    "    else:\n",
    "        opposite = 'src'\n",
    "        \n",
    "    frames = origin.size().repartition(npartitions=1).reset_index()\n",
    "    frames.columns = ['ip',origin_name+'_req']\n",
    "    frames['pop_'+origin_name+'protocol'] = origin['protocol'].apply(lambda x: x.value_counts().index[0], meta=int).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "    frames['nunq_'+origin_name+'protocol'] = origin['protocol'].nunique().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "    frames['pop_'+origin_name+'ip'] = origin[opposite+'addr'].apply(lambda x: x.value_counts().index[0], meta=str).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "    frames['nunq_'+origin_name+'ip'] = origin[opposite+'addr'].nunique().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "    frames['pop_'+origin_name+'port'] = origin[origin_name+'port'].apply(lambda x: x.value_counts().index[0], meta=int).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "    frames['nunq_'+origin_name+'port'] = origin[origin_name+'port'].nunique().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "\n",
    "    \n",
    "    for x,f in enumerate(features):\n",
    "        if f is not 'dur_diff':\n",
    "            frames[origin_name+stats[0]+f] = origin[f].max().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[1]+f] = origin[f].min().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[2]+f] = origin[f].mean().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[3]+f] = origin[f].var().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[4]+f] = origin[f].apply(skw,meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[5]+f] = origin[f].apply(kur,meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "        else:\n",
    "            for i in ['start']:\n",
    "                frames[origin_name+stats[0]+i+'_dur_diff'] = origin[i].apply(lambda x: x.diff().max(), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[1]+i+'_dur_diff'] = origin[i].apply(lambda x: x.diff().min(), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[2]+i+'_dur_diff'] = origin[i].apply(lambda x: x.diff().mean(), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[3]+i+'_dur_diff'] = origin[i].apply(lambda x: x.diff().var(), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[4]+i+'_dur_diff'] = origin[i].apply(lambda x: skw(x.diff()), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[5]+i+'_dur_diff'] = origin[i].apply(lambda x: kur(x.diff()), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                        \n",
    "    frames.name = origin_name\n",
    "    return frames\n",
    "\n",
    "def getall(src,dest,features):\n",
    "    stats = ['max','min','avg','var','skew','kur']\n",
    "    srcframes = buildall(features, stats, src, 'src')\n",
    "    destframes = buildall(features, stats, dest, 'dest')  \n",
    "    return srcframes,destframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildframes(features, stats, origin, origin_name):\n",
    "    frames = origin.size().repartition(npartitions=1).reset_index()\n",
    "    frames.columns = ['ip',origin_name+'_req']\n",
    "\n",
    "    for x,f in enumerate(features):\n",
    "        if f is not 'dur_diff':\n",
    "            frames[origin_name+stats[0]+f] = origin[f].max().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[1]+f] = origin[f].min().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[2]+f] = origin[f].mean().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[3]+f] = origin[f].var().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[4]+f] = origin[f].apply(skw,meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "            frames[origin_name+stats[5]+f] = origin[f].apply(kur,meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "        else:\n",
    "            for i in ['start']:\n",
    "                frames[origin_name+stats[0]+i+'_dur_diff'] = origin[i].apply(lambda x: x.diff().max(), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[1]+i+'_dur_diff'] = origin[i].apply(lambda x: x.diff().min(), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[2]+i+'_dur_diff'] = origin[i].apply(lambda x: x.diff().mean(), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[3]+i+'_dur_diff'] = origin[i].apply(lambda x: x.diff().var(), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[4]+i+'_dur_diff'] = origin[i].apply(lambda x: skw(x.diff()), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                frames[origin_name+stats[5]+i+'_dur_diff'] = origin[i].apply(lambda x: kur(x.diff()), meta=float).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "                        \n",
    "    frames.name = origin_name\n",
    "    return frames\n",
    "               \n",
    "               \n",
    "def getframes(src,dest,features):\n",
    "    stats = ['max','min','avg','var','skew','kur']\n",
    "    srcframes = buildframes(features, stats, src, 'src')\n",
    "    destframes = buildframes(features, stats, dest, 'dest')        \n",
    "    \n",
    "    return srcframes,destframes\n",
    "\n",
    "def build_reduced_frames(origin, origin_name):\n",
    "    if origin_name is 'src':\n",
    "        opposite = 'dest'\n",
    "    else:\n",
    "        opposite = 'src'\n",
    "    frames = origin[opposite+'addr'].nunique().repartition(npartitions=1).reset_index()\n",
    "    frames.columns = ['ip','nunq_'+origin_name+'ip']\n",
    "    #frames['pop_'+origin_name+'protocol'] = origin['protocol'].apply(lambda x: x.value_counts().index[0], meta=int).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "    #frames['pop_'+origin_name+'ip'] = origin[opposite+'addr'].apply(lambda x: x.value_counts().index[0], meta=str).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "    #frames['nunq_'+origin_name+'port'] = origin[origin_name+'port'].nunique().repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "    #frames['pop_'+origin_name+'port'] = origin[origin_name+'port'].apply(lambda x: x.value_counts().index[0], meta=int).repartition(npartitions=1).reset_index().iloc[:,1]\n",
    "\n",
    "    return frames\n",
    "\n",
    "def get_reduced_frames(src,dest):\n",
    "    srcframes = build_reduced_frames(src, 'src')\n",
    "    destframes = build_reduced_frames(dest, 'dest')        \n",
    "    \n",
    "    return srcframes,destframes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 1:\n",
    "    inputfile = '/data/maxim/data/raw_flow_w_rate.csv'\n",
    "    df = dd.read_csv(inputfile)\n",
    "else:\n",
    "    inputfile = '/data/maxim/data/raw_flow_test.csv'\n",
    "    df = dd.read_csv(inputfile, blocksize='2MB')\n",
    "\n",
    "print(df.shape)\n",
    "print(df.npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with LocalCluster(processes=True,n_workers=5,threads_per_worker=2) as cluster:\n",
    "        cluster.adapt(minimum_cores=10,maximum_cores=10,maximum_memory=\"32GB\")\n",
    "        with Client(cluster) as client:\n",
    "            new =  dd.concat([df[\"srcaddr\"].drop_duplicates(),df['destaddr'].drop_duplicates()], axis=0).drop_duplicates().to_frame()\n",
    "            new.columns = [\"ip\"]\n",
    "            newest = new.set_index('ip')\n",
    "            newest = client.persist(newest)\n",
    "            newest.name = 'newest'\n",
    "            wait(newest)\n",
    "            src = df.groupby(['srcaddr'],sort=True)\n",
    "            dest = df.groupby(['destaddr'],sort=True)\n",
    "            features = ['bytes','packets','duration','rate', 'dur_diff']\n",
    "            srcframes, destframes = getall(src,dest,features)\n",
    "            frames = dd.merge(srcframes,destframes, how='outer',on='ip')\n",
    "            newest = dd.merge(newest,frames,how='left',left_index=True, right_on='ip').reset_index(drop=True)\n",
    "            newest['ratio'] = (newest['src_req']/newest['dest_req']).round(decimals=3)\n",
    "            newest = newest.replace([npinf, -npinf], npnan).fillna(0)\n",
    "            newest = client.persist(newest)\n",
    "            wait(newest)\n",
    "            df = client.compute(newest).result()\n",
    "            \n",
    "    print('finished try')\n",
    "    df.to_csv('raw_results_t.csv', index=False)\n",
    "\n",
    "except:\n",
    "    print('started except')\n",
    "    with LocalCluster(processes=True,n_workers=3,threads_per_worker=3) as cluster:\n",
    "        cluster.adapt(minimum_cores=9,maximum_cores=9,maximum_memory=\"32GB\")\n",
    "        with Client(cluster) as client:\n",
    "            new =  dd.concat([df[\"srcaddr\"].drop_duplicates(),df['destaddr'].drop_duplicates()], axis=0).drop_duplicates().to_frame()\n",
    "            new.columns = [\"ip\"]\n",
    "            newest = new.set_index('ip')\n",
    "            newest = client.persist(newest)\n",
    "            newest.name = 'newest'\n",
    "            wait(newest)\n",
    "            src = df.groupby(['srcaddr'],sort=True)\n",
    "            dest = df.groupby(['destaddr'],sort=True)\n",
    "            features = ['bytes','packets','duration','rate', 'dur_diff']\n",
    "            srcframes, destframes = getframes(src,dest,features)\n",
    "            frames = dd.merge(srcframes,destframes, how='outer',on='ip')\n",
    "            newest = dd.merge(newest,frames,how='left',left_index=True, right_on='ip').reset_index(drop=True)\n",
    "            newest['ratio'] = (newest['src_req']/newest['dest_req']).round(decimals=3)\n",
    "            newest = newest.replace([npinf, -npinf], npnan).fillna(0)\n",
    "            newest = client.persist(newest)\n",
    "            wait(newest)\n",
    "            df_origin = client.compute(newest).result()\n",
    "            wait(df_origin)\n",
    "    df_origin.to_csv('origin_results.csv', index=False)\n",
    "    with LocalCluster(processes=True,n_workers=5,threads_per_worker=2) as cluster:\n",
    "        cluster.adapt(minimum_cores=10,maximum_cores=10,maximum_memory=\"32GB\")\n",
    "        with Client(cluster) as client:\n",
    "            new =  dd.concat([df[\"srcaddr\"].drop_duplicates(),df['destaddr'].drop_duplicates()], axis=0).drop_duplicates().to_frame()\n",
    "            new.columns = [\"ip\"]\n",
    "            newest = new.set_index('ip')\n",
    "            newest = client.persist(newest)\n",
    "            newest.name = 'newest'\n",
    "            wait(newest)\n",
    "            src = df.groupby(['srcaddr'],sort=True)\n",
    "            dest = df.groupby(['destaddr'],sort=True)\n",
    "            srcframes, destframes = get_reduced_frames(src,dest)\n",
    "            frames = dd.merge(srcframes,destframes, how='outer',on='ip')\n",
    "            frames = frames.replace([npinf, -npinf], npnan).fillna(0)    \n",
    "            newest = client.persist(newest)\n",
    "            wait(newest)\n",
    "            df_new = client.compute(newest).result()\n",
    "    df = pd.merge(df_origin, df_new, on='ip')\n",
    "    df.to_csv('raw_results_e.csv', index=False)\n",
    "    print('finished except')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with LocalCluster(processes=True,n_workers=5,threads_per_worker=2) as cluster:\n",
    "        cluster.adapt(minimum_cores=9,maximum_cores=9,maximum_memory=\"32GB\")\n",
    "        with Client(cluster) as client:\n",
    "            new =  dd.concat([df[\"srcaddr\"].drop_duplicates(),df['destaddr'].drop_duplicates()], axis=0).drop_duplicates().to_frame()\n",
    "            new.columns = [\"ip\"]\n",
    "            newest = new.set_index('ip')\n",
    "            newest = client.persist(newest)\n",
    "            newest.name = 'newest'\n",
    "            wait(newest)\n",
    "            src = df.groupby(['srcaddr'],sort=True)\n",
    "            dest = df.groupby(['destaddr'],sort=True)\n",
    "            srcframes, destframes = get_reduced_frames(src,dest)\n",
    "            frames = dd.merge(srcframes,destframes, how='outer',on='ip')\n",
    "            newest = dd.merge(newest,frames,how='left',left_index=True, right_on='ip').reset_index(drop=True)\n",
    "            newest = newest.replace([npinf, -npinf], npnan).fillna(0)    \n",
    "            newest = client.persist(newest)\n",
    "            wait(newest)\n",
    "            df_new = client.compute(newest).result()\n",
    "            df_new.to_csv('new_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('new_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.read_csv('origin_results.csv')\n",
    "df_new\n",
    "df = pd.merge(df_origin, df_new, on='ip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"hosts.csv\")\n",
    "results = results.drop(list(((df.columns).intersection(results.columns))[1:]), axis=1)\n",
    "df = pd.merge(df,results, on='ip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from multiprocessing import cpu_count, Pool\n",
    "from netaddr import IPNetwork, IPAddress\n",
    "from ipwhois import IPWhois\n",
    "import swifter\n",
    "import tqdm\n",
    "import socket,struct\n",
    "import pandas as pd\n",
    "import gc\n",
    "gc.enable()\n",
    "\n",
    "def check_in_subnets(ip, subnets):\n",
    "    ip = IPAddress(ip)\n",
    "    for subnet in subnets:\n",
    "        if ip in subnet:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def private_subnets():\n",
    "    ip = ['10.0.0.0','172.16.0.0','192.168.0.0']\n",
    "    mask = [8,12,16]\n",
    "    for i in range(len(ip)):\n",
    "        ip[i] = IPNetwork(ip[i] + '/' + str(mask[i]))\n",
    "    return ip\n",
    "\n",
    "def cu_subnets():\n",
    "    subnets = []\n",
    "    with open('hosts.txt') as reader:\n",
    "        for line in reader.readlines():\n",
    "            l = line.rstrip().split(\" | \")\n",
    "            l[0] = IPNetwork(l[0])\n",
    "            subnets.append(l)\n",
    "    subnets.reverse()\n",
    "    return subnets\n",
    "\n",
    "def check_in_subnets_ret_name(ipstr, subnets):\n",
    "    ip = IPAddress(str(ipstr))\n",
    "    for subnet in subnets:\n",
    "        if ip in subnet[0]:\n",
    "            return subnet[1]\n",
    "    return False\n",
    "\n",
    "def whois(x):\n",
    "    x = str(x).rstrip()\n",
    "    s = check_in_subnets_ret_name(x,subs)\n",
    "    if(s != False):\n",
    "        return s\n",
    "    elif(check_in_subnets(x, p)):\n",
    "        return \"private\"\n",
    "    elif(x == '0'):\n",
    "        return x\n",
    "    else:\n",
    "        try:\n",
    "            obj = IPWhois(x)\n",
    "            results = obj.lookup_whois()\n",
    "            l = [IPNetwork(results['asn_cidr']), results['nets'][0]['name'] + \" - \" + results['nets'][0]['description']]\n",
    "            subs.append(l)\n",
    "            return results['nets'][0]['name'] + \" - \" + results['nets'][0]['description']\n",
    "        except:\n",
    "            try:\n",
    "                return socket.gethostbyaddr(x)\n",
    "            except:\n",
    "                return \"n/a\"\n",
    "        \n",
    "\n",
    "def whoiscu(x):\n",
    "    x = str(x).rstrip()\n",
    "    s = check_in_subnets_ret_name(x,subs)\n",
    "    if(s != False):\n",
    "        return s\n",
    "    elif(check_in_subnets(x, p)):\n",
    "        return \"private\"\n",
    "    elif(x == '0'):\n",
    "        return x\n",
    "    else:\n",
    "        return 'external'\n",
    "            \n",
    "def iscu(x):\n",
    "    x = str(x).rstrip()\n",
    "    s = check_in_subnets(x, subs)\n",
    "    if(s != False):\n",
    "        return True\n",
    "    elif(check_in_subnets(x, p)):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def parallelize(data, func):\n",
    "    pool = Pool(processes = 10)\n",
    "    res = [None]*len(data)\n",
    "    i=0\n",
    "    for x in tqdm.tqdm(pool.imap_unordered(func, data), total=len(data)):\n",
    "        res[i] = x\n",
    "        i += 1\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = private_subnets()\n",
    "subs = cu_subnets()\n",
    "df = pd.read_csv('final.csv')\n",
    "df['internal'] = df['ip'].swifter.allow_dask_on_strings().apply(iscu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df.internal == True\n",
    "df['host'] = 'external'\n",
    "df['pop_srchost'] = 'external'\n",
    "df['pop_desthost'] = 'external'\n",
    "df.loc[mask,'host'] = df.loc[mask,'ip'].swifter.allow_dask_on_strings().apply(whoiscu)\n",
    "df.loc[mask,'pop_srchost'] = df.loc[mask,'pop_srcip'].swifter.allow_dask_on_strings().apply(whoiscu)\n",
    "df.loc[mask,'pop_desthost'] = df.loc[mask,'pop_destip'].swifter.allow_dask_on_strings().apply(whoiscu)\n",
    "#df['pop_srchost'] = df['pop_srcip'].swifter.allow_dask_on_strings().apply(whoiscu)\n",
    "#df['pop_desthost'] = df['pop_destip'].swifter.allow_dask_on_strings().apply(whoiscu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = df.pop('host')\n",
    "df.insert(0, 'host', col)\n",
    "col = df.pop('pop_srchost')\n",
    "df.insert(2, 'pop_srchost', col)\n",
    "col = df.pop('pop_desthost')\n",
    "df.insert(3, 'pop_desthost', col)\n",
    "col = df.pop('dest_req')\n",
    "df.insert(5, 'dest_req', col)\n",
    "col = df.pop('pop_srcport')\n",
    "df.insert(6, 'pop_srcport', col)\n",
    "col = df.pop('pop_destport')\n",
    "df.insert(7, 'pop_destport', col)\n",
    "col = df.pop('pop_srcprotocol')\n",
    "df.insert(8, 'pop_srcprotocol', col)\n",
    "col = df.pop('pop_destprotocol')\n",
    "df.insert(9, 'pop_destprotocol', col)\n",
    "pd.options.display.max_columns = 80\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('final_hosts.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
